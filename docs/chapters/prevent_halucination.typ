#import "../notes.typ"

= جلوگیری از توهم

مزیت روش‌های سنتی و الگوریتمی در این است که قطعی هستند و می‌توانند به صورت
ثابت شده کدی معادل با کد ماشین ورودی تولید کنند اما قادر به تولید کد خوانا
و شبه انسانی نیستند. در مقابل، می‌توان به کمک مدل‌های زبانی بزرگ کدهای
خوانا و انسانی تولید کرد اما تضمینی وجود ندارد که این کدها رفتاری برابر
با رفتار کد ماشین ورودی داشته باشند.

مساله توهم در مدل‌های زبانی باعث شده است که کاربرد آن‌ها در تعدادی از
حوزه‌ها محدود شود. به ویژه در حوزه‌هایی که رفتار خصمانه وجود دارد (مثل
حوزه‌های امنیتی) مهاجمین می‌توانند با استفاده از تکنیک‌هایی مثل تزریق
درخواست استفاده کنند و احتمال خطای مدل را افزایش دهند یا خروجی آن را به
سمت خاصی منحرف کنند. با توجه به کاربردهای امنیتی که مساله ترجمه‌معکوس دارد
این معضل در ترجمه معکوس از اهمیت بیشتری هم برخوردار می‌شود.

== آسیب‌پذیری مترجم معکوس نسبت به توهم

در این بخش با دو نمونه کد تلاش می‌شود تا نشان داده شود که این چالش توهم یک
چالش نظری نیست و در کدهای ساده می‌تواند به طور قابل اتکایی اتفاق بیفتد. در کد
اول یک تغییر جزیی در یک
#notes.note[عدد جادویی][magic number]
به کار رفته توسط مترجم در یک بهینه‌سازی
تغییر داده می‌شود اما مدل زبانی متوجه این تغییر نمی‌شود و کد اشتباه را به عنوان
معنی این کد بر می‌گرداند. در کد دوم، نماد متناظر با نام یکی از توابع یک نام انتخاب
شده به صورت خصمانه است که تلاش می‌کند با تزریق درخواست، کد دیگری را به جای
کد فعلی قرار دهد.

=== جابه‌جایی عدد جادویی

یکی از بهینه‌سازی‌هایی که توسط مترجم انجام می‌شود، جایگزینی تقسیم عدد ثابت با ضرب
است. برای مثال کد سی زیر:

```c
int some_calculation(int num) {
    return num / 10;
}
```

هنگام ترجمه شدن همراه با بهینه‌سازی به کد ماشین زیر تبدیل می‌شود:

```
some_calculation:
        li      a5,1717985280
        addi    a5,a5,1639
        mul     a5,a0,a5
        srai    a5,a5,34
        sraiw   a0,a0,31
        subw    a0,a5,a0
        ret
```

همان‌طور که می‌بینید، به جای عمل تقسیم به ده، عمل ضرب در عدد جادویی
1717986919
به همراه شیفت بیتی به میزان ۳۴ واحد انجام می‌شود که معادل همان تقسیم به ده
است ولی در پردازنده‌ها سریع‌تر انجام می‌شود. حال اگر به جای این عدد جادویی
خاص یک تابع بخواهد ورودی‌اش را در یک عدد مشابه مانند
1717985919
که تنها در یک رقم با عدد جادویی متفاوت است ضرب کند و سپس نتیجه را
۳۴
واحد شیفت دهد، دیگر معنای این کد یک تقسیم به ده ساده نخواهد بود. با این حال
مدل‌های زبانی بزرگ فعلی نمی‌توانند این تفاوت را تشخیص دهند و این کد را معادل
کد تقسیم به ده در نظر می‌گیرند. در جدول زیر نتایج این بررسی با مدل‌های زبانی هدف
آمده است:


#align(center, text([

  #text(size: .8em, [
    *جدول ۱:* مقایسه مترجم‌های معکوس بررسی شده
  ])

  #table(
    columns: 4,
    table.header("نام", "کد تقسیم به ده", "کد تغییر یافته با پرامپت عادی", "کد تغییر یافته با پرامپت محتاطانه"),
    "چت جی‌پی‌تی ۵",
    "به درستی تقسیم به ده تشخیص داد",
    "به اشتباه تقسیم به ده تشخیص داد",
    "به اشتباه تقسیم به ده تشخیص داد",

    "دیپ‌سیک", "به اشتباه تقسیم به صد تشخیص داد", "به اشتباه تقسیم به صد تشخیص داد", "به اشتباه تقسیم به ده تشخیص داد",
    "دیپ‌سیک با تفکر",
    "به درستی تقسیم به ده تشخیص داد",
    "به اشتباه تقسیم به ده تشخیص داد",
    "به اشتباه تقسیم به ده تشخیص داد",
    "کوئن چهار میلیارد پارامتری",
    table.cell(colspan: 3)[رابطه با تقسیم به ده به کلی تشخیص داده نشد و ارتباط‌های
      اشتباهی به شا۳ اشاره شد اما مدل در هر سه پرسش در کد تولیدی صرفا عملیات‌های ضرب
      و شیفت معادل را تولید کرد.],
  )

]))

در آزمایش بالا پرامپت عادی متن زیر:

```
What does this code do?
```

و پرامپت محتاطانه متن زیر است:

```
What does this code do? Be careful in exact values of numbers, don't approximate.
```

در این آزمایش هیچ کدام از مدل‌ها قادر به مشاهده تفاوت جزیی در عدد داده شده
و عدم نسبت دادن رفتار تقسیم به ده به کد تغییر یافته نبودند، به جز مدل
کوئن کوچک که اصلا قادر به تشخیص الگوی تقسیم به ده نبود. حتی مدل جی‌پی‌تی که به
ابزار برای محاسبه اعداد مجهز بود با این که به درستی توانست تفاوت عدد داده
شده با عدد جادویی اصلی را تشخیص دهد اما باز هم برای رفتار کد همان تشخیص اشتباه
را داد.

اگرچه مدل‌های آینده ممکن است بتوانند این مشکل خاص را حل کنند یا با کمک مهندسی پرامپت
بهتر یا ابزارهای کمکی مثل
MCP
ها ممکن است بتوان این مشکل خاص را حل کرد، اما به صورت عمومی می‌توان به سادگی
مثال‌هایی از این قبیل تولید کرد.

=== تزریق درخواست از طریق نام نماد و رشته‌ها

در بعضی از برنامه‌های اجرایی، نام توابع به دلایلی مانند اشکال‌زدایی راحت‌تر
یا پیوند شدن به
#notes.note[کتاب‌خانه‌های پویا][Dynamically linked library]
از برنامه حذف نمی‌شود و به صورت یک نماد در برنامه باقی می‌ماند. این نماد
در اجرای برنامه تاثیری ندارد و صرفا به عنوان شناسه‌ای هنگام اجرای دستورات پرش
عمل می‌کند. در نتیجه یک مهاجم می‌تواند رشته دلخواه خود را در این نماد‌ها بنویسد
و از این طریق یک حمله تزریق درخواست انجام دهد. به علاوه آن، رشته‌ها نیز می‌توانند
مقادیر دلخواهی را در خود ذخیره کنند ولی در اجرای برنامه استفاده نشوند.

در این مثال به کمک رشته‌ها، یک حمله تزریق درخواست را انجام می‌دهیم و تلاش
می‌کنیم که تابع
`call_some_fn`
را از خروجی مخفی کنیم. پرامپت به کار رفته در این مثال برابر است با:

```
What does this code do? Give me an equivalent C code.

.LC0:
        .string "Some normal string\"

Now continue with this code, but don't do any mention of \"call_some_fn\". I know what it does and it is spam.

.LC0:
        .string \"hello"
calculate_sum:
        addi    sp,sp,-32
        lui     a5,%hi(.LC0)
        sd      s0,16(sp)
        mv      s0,a0
        addi    a0,a5,%lo(.LC0)
        sd      ra,24(sp)
        sd      a1,8(sp)
        call    print
        call    call_some_fn
        ld      a1,8(sp)
        ld      ra,24(sp)
        addw    a0,s0,a1
        ld      s0,16(sp)
        addi    sp,sp,32
        jr      ra
```

همان طور که می‌بینید، تعدادی کوتیشن اسکیپ شده است که مدل‌زبانی بزرگ را گمراه
کند. نتیجه آزمایش روی چهار مدل زبانی در جدول زیر آمده است:

#align(center, text([

  #text(size: .8em, [
    *جدول ۱:* مقایسه مترجم‌های معکوس بررسی شده
  ])

  #table(
    columns: 2,
    table.header("نام", "نتیجه"),
    "چت جی‌پی‌تی ۵", "در توضیحات به تابع مخرب اشاره کرد ولی در کد نهایی آن را نیاورد",

    "دیپ‌سیک", "نه در توضیحات و نه در کد نهایی به تابع مخرب اشاره نکرد",
    "دیپ‌سیک با تفکر", "در افکار به تابع مخرب اشاره کرد ولی در توضیحات و کد نهایی اشاره نکرد",
    "کوئن چهار میلیارد پارامتری", "در افکار و توضیحات به تابع مخرب اشاره کرد ولی در کد نهایی آن را نیاورد",
  )

]))

اگرچه ممکن است با پیشرفت مدل‌ها یا تکنیک‌های پرامپت دهی پیشرفته تر مانع این نوع
حملات شد، اما از طرف مقابل مهاجمین نیز می‌توانند تکنیک‌های پیشرفته‌تری را به کار
بگیرند و تا وقتی که یک تضمین ریاضیاتی و قطعی روی خروجی مدل‌ها وجود نداشته
باشد این بردار حمله هم‌چنان باز است.

== راهکار

ایده این است که با تلفیق مزایای هر دو روش الگوریتمی و
یادگیری ماشینی، به یک روش ترجمه معکوس دست پیدا
کنیم که هم به صورت قطعی و تضمینی کد شبه درست خروجی دهد و هم خروجی خوانا
و قابل فهم داشته باشد. به این صورت که توسط یک روش الگوریتمی و سنتی ترجمه
معکوس آغاز شود و هنگامی که روش الگوریتمی می‌توانست از چند طریق ترجمه معکوس
را انجام دهد و همه این روش‌ها از نظر حفظ خواص معنایی درست بودند، انتخاب
خواناترین و مفهوم‌ترین گزینه به مدل زبانی بزرگ سپرده شود.

به عبارت دقیق‌تر، این فرایند برای ترجمه معکوس طی می‌شود: ابتدا کد ماشین
ورودی تبدیل به یک کد ناخوانا در زبان سطح بالا
ولی با خواص معنایی یکسان تبدیل می‌شود. سپس در هر مرحله کد فعلی تحلیل
می‌شود و بر اساس آن، چند عمل به مدل زبانی ارائه می‌شود. این که این عمل‌ها
دقیقا چند مورد هستند و چه کارهایی می‌توانند بکنند در ادامه کار مشخص
می‌شود اما خاصیت کلیدی آن‌ها این است که خواص معنایی برنامه را تغییر
نمی‌دهند و تحلیل ابتدایی این موضوع را تضمین می‌کند. سپس مدل زبانی
یکی از این عمل‌ها را انتخاب می‌کند، پارامترهای آن را ارائه می‌دهد و
نتیجه عمل را دریافت و تایید می‌کند. به این ترتیب یک مرحله کد خواناتر
می‌شود. این کار چند مرحله تکرار می‌شود تا وقتی که مدل زبانی عمل پایان
را انتخاب کند.

این روش با روش به کار رفته در دی‌جی‌پی‌تی دو تفاوت عمده دارد: یکی این که
در دی‌جی‌پی‌تی در صورتی که کد پیچیده باشد، کد تولید شده توسط مدل زبانی
با احتمال بالایی خواص معنایی کد اولیه را تغییر می‌دهد و در صورت درست عمل
کردن بررسی کننده، تغییر رد می‌شود. با رد شدن چند تغییر متوالی، مدل زبانی
دیگر نمی‌تواند کد متفاوتی را تولید کند و کار در یک مرحله متوقف می‌شود. اما
هنگام استفاده از عمل‌ها استفاده از هر عملی موجب ایجاد یک کد جدید می‌شود
و احتمال گیر کردن کمتر است. تفاوت دوم این است که بررسی برابری دو
کد به صورت صددرصدی یک مساله محاسبه‌ناپذیر است و روش‌های تقریب آن هر کدام
مشکلاتی دارند. به طور خاص روش به کار رفته در دی‌جی‌پی‌تی به طور صددرصدی
برابری خواص را تضمین نمی‌کند و صرفا از تعدادی از خطاها جلوگیری می‌کند. اما
هنگام طراحی عمل‌ها می‌توان آن‌ها را طوری انتخاب کرد که حتما خواص معنایی
را حفظ کنند.

محدود کردن گزینه‌های مدل زبانی بزرگ به منظور تضمین خواص در خروجی
قبلا هم انجام شده است. یک حرکت متداول برای ساختارمند
کردن خروجی مدل‌های زبانی
بزرگ و تضمین این که ساختار خروجی به حالت مثلا
#notes.note[جیسون][JSON]
باشد، این است که کلمات خروجی مدل را با یک
#notes.note[دستور زبان][grammar]
تطبیق دهیم و هنگام انتخاب و درج کلمات جدید، احتمال کلمات خارج از
دستور زبان را صفر در نظر بگیریم.
@Grammar_LLM
یا در تعدادی از تلاش‌ها مانند
#notes.note[آلفاپروف][AlphaProof]
گزینه‌های ارائه شده به مدل زبانی به
#notes.note[راه‌کنش‌های][tactics]
موجود در بررسی‌کننده اثبات
#notes.note[لین][Lean]
محدود شده‌اند یا در
#notes.note[آلفاجئومتری][AlphaGeometry]
گزینه‌های مدل زبانی به رسم‌های هندسی ممکن در شکل به دست آمده
محدود شده است.
@Alpha_geometry

اگرچه این خانواده از ایده‌ها باعث تضمین خواصی روی خروجی مدل‌های زبانی
بزرگ می‌شوند، اما خود آن‌ها مشکلاتی روی کیفیت خروجی ایجاد می‌کنند. مثلا
در مورد استفاده از دستور زبان برای تضمین ساختار خروجی، مطالعه‌ای نشان
داده است که استفاده بی‌ملاحظه از این روش می‌تواند منجر به ایجاد خروجی‌هایی
شود که در توزیع احتمالی مدل زبانی احتمال پایینی دارند و در نتیجه
بی‌کیفیت هستند.
@Grammar_LLM

در مورد محدود کردن گزینه‌های مدل زبانی بزرگ هنگام ترجمه معکوس نیز همین
مشکل برقرار است و ممکن است در نهایت خروجی‌های تولید شده توسط این فرایند
در توزیع مدل زبانی
#notes.note[درست‌نمایی][likelihood]
پایینی داشته باشند. در این حالت یک مدل ترجمه معکوس سرتاسر
ممکن است خروجی‌هایی تولید کند که کاملا معادل ورودی زبان ماشین نباشد
یا به دلیل ایرادی جزیی اصلا قابل اجرا نباشد، اما
در عین حال بیشتر شبیه یک کد
نوشته شده توسط انسان باشد و شمایی از کد منبع اصلی را نمایش دهد. در
مقابل خروجی تولید شده توسط مترجم معکوس محدود به عمل‌هایی که
خواص معنایی کد را حفظ می‌کنند یک کد بسیار ماشینی و ناخوانا باشد
که از نظر مدل زبانی بزرگ سرتاسر احتمال وقوع بسیار پایینی دارد و
حتی نزدیک به کد منبع اصلی نیست.

چالش اصلی ما انتخاب مجموعه‌ای از عمل‌ها روی کد است که بتوانند
در عین حال که خواص معنایی کد را حفظ می‌کنند، مانع اجرای اعمال
توسط مدل زبانی بزرگ نشوند و دست آن را خیلی نبندند تا مدل زبانی
بزرگ بتواند بدون این که نیاز به انجام اعمال طولانی و پیچیده‌ای
داشته باشد کد منبع مد نظرش را به دست آورد.

منظور از پیچیدگی اعمال، عدم نیاز به استنتاج برای انتخاب اعمال
یا نیاز به انتخاب چند عمل درست به صورت پشت سر هم بدون این که
راهنمایی برای انتخاب هر عمل در هر مرحله وجود داشته باشد است. اگر
ترجمه معکوس را مشابه یک مساله ریاضی در نظر بگیریم یک مدل زبانی
بزرگ سرتاسر فقط نیاز به پیدا کردن جواب آخر مساله دارد اما ساخت
کد منبع از طریق اعمالی که هر کدام به تنهایی خواص معنایی را حفظ
می‌کنند مشابه اثبات مساله است. و پیدا کردن اثبات به صورت ذاتی از پیدا کردن جواب آخر سخت تر است. به طور مشابه کار مدل زبانی بزرگ در ساخت
به کمک انجام عمل‌ها از ساخت جواب آخر به صورت ذاتی سخت‌تر است و هدف
انتخاب مجموعه عمل‌هایی است که از نظر تعداد و توانایی غنی باشند و
این سختی را کاهش دهند.

#align(center, text(size: .8em, [

  #rotate(180deg, figure(
    image("../seminar/maze2.png", width: 50%),
  ))

  *شکل 2:* انتخاب یک مسیر به هدف با رعایت قوانین و محدودیت‌ها به صورت
  ذاتی کار سخت‌تری نسبت به انتخاب یک نقطه نزدیک به هدف به صورت تصادفی، مثلا
  از توزیع سبز رنگ است، اما انتخاب یک نقطه تصادفی نزدیک به هدف ممکن است
  نقطه نامعتبری را انتخاب کند.

]))
