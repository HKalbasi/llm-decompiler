#import "../notes.typ"

= پژوهش‌های پیشین

تا قبل از پدید آمدن شبکه‌های عصبی، فرایندهای ترجمه معکوس از روش‌های
سنتی استفاده می‌کردند. در این روش‌ها، که امروزه نیز اکثر مترجمین معکوس
صنعتی از آن‌ها استفاده می‌کنند، متخصصان و دانشمندان رایانه به صورت
دستی قواعد و الگوریتم‌هایی برای ترجمه‌معکوس به ازای دستورها و الگوهای
خاص کد زبان ماشین به دست می‌آوردند و در صورت تطبیق پیدا کردن
آن قاعده، کد ماشین را با کد سطح بالای از پیش تعریف شده جایگزین
می‌کردند. در
@Retargetable
تاریخچه پنجاه ساله مترجم‌های معکوس بررسی شده است. این روش‌ها نیاز به
توسعه فراوانی دارند. مثلا مترجم معکوس گیدرا از یک و نیم میلیون خط
کد تشکیل شده است یا طبق ادعای شرکت سازنده مترجم رت‌دک
این مترجم برای کامل شدن به یک تیم خبره ۲۴ نفره نیاز دارد که هفت سال
روی آن کار کنند.
@RetDec
به علاوه، با تمام این تلاش‌ها، خروجی این نوع مترجم‌ها خوانایی خوبی
ندارد و تا حد زیادی از یک کد عادی فاصله دارد.

#align(center, text(size: .8em, [

#figure(
  image("../seminar/ghidra.png", width: 50%),
)

*شکل ۱:* نمونه خروجی گیدرا که در آن به دلیل عدم انتخاب نام و نوع
مناسب برای ورودی‌ها و متغیرها، کد ناخوانایی تولید شده است.

]))

استفاده از روش‌های شبکه عصبی و یادگیری ماشین در زمینه ترجمه معکوس قبل از
مدل‌های زبانی بزرگ نیز انجام شده است. مثلا
#notes.note[کودا][Coda]
@Coda
و
#notes.note[نوترون][Neutron]
@Neutron
از یک
#notes.note[شبکه عصبی بازگشتی][recurrent neural network]
به همراه چند لایه دیگر از جمله لایه توجه استفاده می‌کنند و به کمک آن
می‌تواند کد‌های کوچک را با دقت پایینی ترجمه معکوس کنند. یا کاری دیگر
@Variable_for_decompiled
برای بازیابی نام متغیرها از یک مدل
#notes.note[ترجمه ماشینی آماری][statistical machine translation]
استفاده می‌کند.

با ظهور مدل‌های زبانی بزرگ، استفاده مدل‌های شبکه عصبی در ترجمه معکوس وارد
مرحله جدیدی شد. این مدل‌ها با استفاده از میلیارد‌ها ویژگی، قادر به بررسی
و تولید دنباله‌هایی با طول هزاران کلمه هستند و با یادگرفتن روی ترابایت‌ها
داده از اینترنت، ویژگی‌های قابل توجهی مثل تولید کد از زبان طبیعی در آن‌ها
ظهور پیدا کرده است. درک این مدل‌ها از کد این امید را ایجاد می‌کند که این
مدل‌ها بتوانند روی وظیفه ترجمه معکوس نیز خوب عمل کنند و پژوهش‌هایی در
این زمینه انجام شده است.

با این حال استفاده از مدل‌های زبانی بزرگ عام منظوره در وظیفه ترجمه معکوس
خوب عمل نمی‌کند زیرا در دادگان ورودی این مدل‌ها کد به زبان ماشین وجود
نداشته‌است یا درصد آن بسیار ناچیز بوده است. مثلا انجام ترجمه معکوس
به کمک
#notes.note[چت‌جی‌پی‌تی][ChatGPT]
که یک مدل زبانی بزرگ عام منظوره است نتایجی با
#notes.note[نزدیکی ویرایشی][edit similarity]
کمتر از چهل درصد و
#notes.note[دقت ورودی خروجی][IO accuracy]
کمتر از بیست درصد
@SLaDe
به دست آورده است. در زبان جاوا با معیار اجرای موفق مجدد
#notes.note[آزمون‌های واحد][unit tests]
چت‌جی‌پی‌تی موفق به دستیابی به درصدهای نزدیک به هشتاد شده است
@Chatgpt_Java
که این مساله به خاطر غنی‌تر بودن و سطح بالاتر بودن کد ماشین مجازی جاوا
است اما با این حال نیز تفاوت خاصی بین چت‌جی‌پی‌تی و مترجم معکوس‌های
قبلی وجود ندارد.

پروژه
#notes.note[اسلید][SLaDe]
یک مدل زبانی با ۲۰۰ میلیون ویژگی ارائه می‌دهد
@SLaDe
که با معماری
#notes.note[ترنسفرمر][Transformer]
به صورت سرتاسر روی مجموعه دادگان
#notes.note[اگزه‌بنچ][ExeBench]
که یک دادگان شامل توابع کوچک به زبان سی و نسخه ترجمه شده آن است
@ExeBench
آموزش دیده شده است و نتایج بهتری از
پروژه گیدرا و استفاده از چت‌جی‌پی‌تی به صورت خام به دست آورده است و در
بعضی از
#notes.note[محک‌ها][Benchmark]
توانسته است تا چهار برابر از مترجم معکوس‌های قبلی بهتر باشد. پروژه دیگری
به کمک
#notes.note[تنظیم دقیق][fine tune]
مدل
#notes.note[برت][BERT]
تلاش کرده تا نام متغیرها را در ترجمه معکوس بازیابی کند.
@ٰBERT_variable
یک تلاش دیگر، مدل
#notes.note[دیپ‌سیک‌کدر][DeepSeek-coder]
هفت میلیارد پارامتری روی دادگان اگزه‌بنچ تنظیم دقیق شده است و نتایح بهتری
نسبت به اسلید و دیپ‌سیک‌کدر خام به دست آورده است.
@llm4decompile

یکی از کارهای دیگر در این زمینه
#notes.note[دی‌جی‌پی‌تی][DeGPT]
@DeGPT
است که در بین پژوهش‌های مطالعه شده شاید نزدیک‌ترین مورد به ایده مطرح
شده باشد. در دی‌جی‌پی‌تی ابتدا ترجمه معکوس توسط یک مترجم معکوس پایه
انجام می‌شود و سپس مدل زبانی بزرگ در قالب سه
#notes.note[عامل][Agent]
داور و مشاور و مجری در چند مرحله خروجی مترجم معکوس
پایه را بهبود می‌دهند. در هر مرحله عامل داور تعیین می‌کند که آیا خروجی
نیاز به بهبود دارد یا خیر و اگر نیاز به بهبود دارد جنس بهبود را
از بین افزودن نظر، تغییر نام متغیرها یا ساده‌سازی ساختار کد انتخاب
می‌کند. سپس عامل مشاور متن درخواست را برحسب تغییر انتخاب شده به عامل
مجری می‌فرستد و عامل مجری، کد جدید را تولید می‌کند. سپس کد تغییر یافته
با اعداد تصادفی آزمایش می‌شود و در صورتی که نتیجه آن برابر با کد
ورودی اصلی بود، رفتار آن معادل با کد اولیه در نظر گرفته می‌شود و
فرایند تکرار می‌شود.

#align(center, text([

#text(size: .8em, [
*جدول ۱:* مقایسه مترجم‌های معکوس بررسی شده
])

#table(columns: 4, 
table.header("نام", "روش کارکرد", "خوانایی خروجی", "دقت خروجی"),
"گیدرا", "قواعد و الگوریتم‌های دستی", "کم", "با تنظیماتی که خوانایی را کاهش دهد می‌تواند زیاد باشد",
"کودا", "ال‌اس‌تی‌ام درختی + توجه", "زیاد در کدهای بسیار کوچک", "زیاد در کدهای بسیار کوچک",
"آلان جافی و سایرین", "ترجمه ماشینی آماری", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
"اسلید", "ترنسفرمر", "متوسط", "متوسط",
"بانرجی و وانگ", "برت", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
"ال‌ال‌ام برای ترجمه معکوس", "مدل زبانی بزرگ تنظیم دقیق شده", "زیاد", "متوسط",
"دی‌جی‌پی‌تی", "مدل زبانی بزرگ به صورت چند عاملی", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
)

]))

با تمام پیشرفت‌هایی که حاصل شده است، استفاده از مدل‌های زبانی بزرگ در
ترجمه معکوس مشکلات بنیادینی دارد. به دلیل ذات احتمالاتی این مدل‌ها، آن‌ها
هیچ وقت نمی‌توانند به دقت صددرصدی برسند. اگرچه روش‌های سنتی ترجمه معکوس
نیز دقت صددرصدی را فدای خوانایی بیشتر کد خروجی می‌کنند و در زمان تولید
کد با بیشترین خوانایی، درصد کدهای اشتباهشان حتی از روش‌های بر پایه
مدل‌های زبانی بزرگ بیشتر است، اما می‌توان آن‌ها را طوری تنظیم کرد که
در قبال خوانایی کمتر کد خروجی، حتما خواص
#notes.note[معنایی][semantic]
کد ماشین ورودی را حفظ کنند. اما در روش‌هایی که به صورت سرتاسر از
یک مدل زبانی بزرگ استفاده می‌شود و کد خروجی مستقیما توسط مدل تولید
می‌شود، نمی‌توان تضمین کرد که کد تولید شده معادل کد ماشین ورودی
اجرا شود یا حتی اصلا معتبر باشد. مثلا ممکن است که مدل زبانی بزرگ
دچار توهم شود و تابعی را صدا کند که اصلا وجود خارجی ندارد و در نتیجه
کد قابل اجرا نباشد.
@Hallucinations
در بدترین حالت، یک مهاجم می‌تواند از این عدم تضمین سواستفاده کرده و
تلاش کند تا خروجی مترجم معکوس کارکرد نرم‌افزار ورودی را نمایش ندهد. مثلا
یک بدافزار می‌تواند از طریق
#notes.note[تزریق درخواست][prompt injection]
در نام یکی از نمادها خروجی مترجم معکوس را تحت الشعاع قرار دهد و محققی
که در حال مطالعه این بدافزار است را گمراه کند.
@Prompt_injection
