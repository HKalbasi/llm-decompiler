#import "notes.typ"

#set text(
  dir: rtl,
  font: "B Nazanin"
)
#set page(
  paper: "a4",
)

#figure(
  image("logo.png", width: 30%),
)

#v(1cm)

#align(center, text(weight: "bold", top-edge: 0.4em)[

دانشگاه صنعتی شریف

دانشکده مهندسی کامپیوتر

سمینار کارشناسی ارشد گرایش هوش مصنوعی

#v(1cm)

عنوان:

بهبود خروجی مترجم معكوس به كمک مدل‌های زبانی بزرگ

Improving decompiler's output using large language models

#v(1cm)

نگارش:

حمیدرضا کلباسی

۴۰۲۲۱۱۴۴۵

#v(1cm)

استاد راهنما:

دکتر محمد ایزدی

#v(1cm)

استاد ممتحن داخلی:

دکتر احسان‌الدین عسگری

#v(3.5cm)

بهمن ۱۴۰۳

])

#pagebreak()

#set page(
  numbering: "1",
  number-align: center,
)

#set par(
  justify: true,
)

*چکیده:*
#notes.note[مترجم معکوس][decompiler]
ابزاری است که کد تولید شده زبان ماشین توسط یک
#notes.note[مترجم][compiler] 
را به کد منبع اصلی بر می‌گرداند. مشکل فرایند ترجمه معکوس این است که
اطلاعات سطح بالا مثل نام متغیر‌ها یا ساختار‌های سطح بالای کد در فرایند
ترجمه از دست رفته است. چون این اطلاعات مرتبط به زبان طبیعی‌اند
#notes.note[مدل‌های زبانی بزرگ][large language models]
گزینه مناسبی برای بازیابی این اطلاعات هستند اما این مدل‌ها چالش‌هایی
مانند
#notes.note[توهم][hallucination]
دارند. هدف این پژوهش استفاده از
مدل‌های زبانی بزرگ در مترجم معکوس و رفع چالش‌هاست. در این گزارش ابتدا به
طرح مساله می‌پردازیم، سپس پژوهش‌های پیشین را بررسی می‌کنیم، وضعیت
ایده فعلی را شرح می‌دهیم و در انتها برنامه آینده را بررسی می‌کنیم.

*واژه‌های کلیدی:* مترجم معكوس، مدل‌های زبانی بزرگ، زبان‌های برنامه‌سازی

= ۱ #h(0.5cm) مقدمه

در بسیاری از زبان‌های برنامه‌سازی، 
#notes.note[کد منبع][source code]
تحت فرایندی به نام
#notes.note[ترجمه][compile] 
به کد زبان ماشین تبدیل می‌شود و نرم‌افزار به صورت کد زبان ماشین منتشر
و اجرا می‌شود. با این حال، کد زبان ماشین برای انسان خوانا نیست و برای
فهم نحوه عملکرد نرم‌افزار نیاز به کد منبع است. ترجمه معکوس فرایندی است
که در آن تلاش می‌شود از کد زبان ماشین خروجی یک مترجم، کد منبع بازیابی
شود.

به طور کلی کاربرد مترجم معکوس در زمینه مهندسی معکوس و به دست آوردن
کد منبع و نحوه عملکرد نرم‌افزارهایی است که به همراه کد منبع توزیع
نشده‌اند و کد منبع آن‌ها در دسترس نیست. به کمک ترجمه معکوس می‌توان
معادل کد منبعی که در دسترس نبود را به دست آورد و به کمک آن، نحوه
عملکرد نرم‌افزار را مطالعه کرد یا نسخه تغییریافته‌ای از آن را به وجود آورد.

یکی از کاربردهای مترجم معکوس در زمینه امنیت نرم‌افزار است و شرکت‌ها و
موسسات امنیتی روی بهبود مترجم‌های معکوس سرمایه گذاری کرده‌اند. مثلا
یکی از مترجم‌های مطرح پروژه
#notes.note[گیدرا][Ghidra]
است که توسط سازمان امنیت ملی امریکا توسعه داده شده است و به صورت
#notes.note[متن‌باز][Open Source]
در اختیار عموم قرار داده شده است. یا یک شرکت امنیتی به نام
#notes.note[اواست][Avast]
مترجم معکوس
#notes.note[رت‌دک][RetDec]
را توسعه داده است.
@RetDec
متخصصان امنیت نرم‌افزار به کمک ابزارهای مترجم معکوس می‌توانند بدافزارها
یا نرم‌افزارهای آسیب‌پذیر را مهندسی معکوس کرده و از طرز عملکرد آن‌ها
مطلع شوند.

یک کاربرد دیگر مترجم معکوس، بازیابی کدهای از دست رفته است. در صورتی
که به خوبی از یک کد منبع مراقبت نشود ممکن است به تدریج کدها
از بین بروند اما نسخه اجرایی آن‌ها که در حال استفاده است هنوز
وجود داشته باشد. در این صورت به کمک مترجم معکوس می‌توان کدهای از دست
رفته را به دست آورد. حتی در زمانی که یک نرم‌افزار توسط شرکت سازنده
آن رها شده است یا شرکت سازنده آن منحل شده است می‌تواند به کمک ترجمه معکوس
جان دوباره‌ای بگیرد و توسعه آن توسط افراد مستقل ادامه پیدا کند. استفاده
از مترجم معکوس در این زمینه برای نرم‌افزارها و به ویژه بازی‌های قدیمی
متداول است. البته در این نوع استفاده باید به رعایت قوانین حق تکثیر
نیز توجه کرد.

قابل توجه است که برای بسیاری از کاربردها، نیازی نیست که ترجمه معکوس
دقیقا کد ابتدایی که تحت فرایند ترجمه به کد ماشین فعلی تبدیل شده است
را به دست آورد و صرف این که یک کد خوانا و شبه انسانی در زبان سطح بالا
تولید کند که معادل کد ماشین داده شده باشد و در عین حال برای انسان
قابل فهم باشد کافی است.

با این حال حتی برای ایجاد یک کد خوانای معادل کد ماشین ورودی نیز چالش‌هایی
وجود دارد. مساله تشخیص کد خوانا از ناخوانا و تولید کد خوانا ذاتا یک
مساله خوش تعریف ریاضیاتی نیست و روش‌های سنتی که به صورت الگوریتمی
کار می‌کنند قادر به ارائه یک کد خوانا و انتخاب خواناترین کد از میان
چند گزینه نیستند. مثلا به صورت الگوریتمی نمی‌توان نام مناسبی را برای
یک متغیر انتخاب کرد. با ظهور شبکه‌های عصبی و مدل‌های زبانی بزرگ پیشرفت
بزرگی در درک زبان‌های طبیعی و ایجاد متن و کد با رعایت محدودیت‌های زبان
طبیعی به وجود آمده است. مثلا خوانایی یک کد می‌تواند با احتمال وقوع
آن در توزیع احتمالاتی یک مدل زبانی مدل سازی شود.

اگرچه مدل‌های زبانی بزرگ می‌توانند به صورت مستقیم و سرتاسر فرایند ترجمه
معکوس را انجام دهند، اما به دلیل ذات احتمالاتی آن‌ها، چالش‌هایی مانند
توهم برای آن‌ها وجود دارد. برای حل این مشکل، ما از ترکیب روش‌های
الگوریتمی و مدل زبانی استفاده می‌کنیم، به این صورت که به روش الگوریتمی
چند گزینه که همه آن‌ها معادل کد ورودی هستند را به دست می‌آوریم و به
کمک مدل زبانی خواناترین این گزینه‌ها را انتخاب می‌کنیم.

= ۲ #h(0.5cm) پژوهش‌های پیشین

تا قبل از پدید آمدن شبکه‌های عصبی، فرایندهای ترجمه معکوس از روش‌های
سنتی استفاده می‌کردند. در این روش‌ها، که امروزه نیز اکثر مترجمین معکوس
صنعتی از آن‌ها استفاده می‌کنند، متخصصان و دانشمندان رایانه به صورت
دستی قواعد و الگوریتم‌هایی برای ترجمه‌معکوس به ازای دستورها و الگوهای
خاص کد زبان ماشین به دست می‌آوردند و در صورت تطبیق پیدا کردن
آن قاعده، کد ماشین را با کد سطح بالای از پیش تعریف شده جایگزین
می‌کردند. در
@Retargetable
تاریخچه پنجاه ساله مترجم‌های معکوس بررسی شده است. این روش‌ها نیاز به
توسعه فراوانی دارند. مثلا مترجم معکوس گیدرا از یک و نیم میلیون خط
کد تشکیل شده است یا طبق ادعای شرکت سازنده مترجم رت‌دک
این مترجم برای کامل شدن به یک تیم خبره ۲۴ نفره نیاز دارد که هفت سال
روی آن کار کنند.
@RetDec
به علاوه، با تمام این تلاش‌ها، خروجی این نوع مترجم‌ها خوانایی خوبی
ندارد و تا حد زیادی از یک کد عادی فاصله دارد.

#align(center, text(size: .8em, [

#figure(
  image("ghidra.png", width: 50%),
)

*شکل ۱:* نمونه خروجی گیدرا که در آن به دلیل عدم انتخاب نام و نوع
مناسب برای ورودی‌ها و متغیرها، کد ناخوانایی تولید شده است.

]))

استفاده از روش‌های شبکه عصبی و یادگیری ماشین در زمینه ترجمه معکوس قبل از
مدل‌های زبانی بزرگ نیز انجام شده است. مثلا
#notes.note[کودا][Coda]
@Coda
و
#notes.note[نوترون][Neutron]
@Neutron
از یک
#notes.note[شبکه عصبی بازگشتی][recurrent neural network]
به همراه چند لایه دیگر از جمله لایه توجه استفاده می‌کنند و به کمک آن
می‌تواند کد‌های کوچک را با دقت پایینی ترجمه معکوس کنند. یا کاری دیگر
@Variable_for_decompiled
برای بازیابی نام متغیرها از یک مدل
#notes.note[ترجمه ماشینی آماری][statistical machine translation]
استفاده می‌کند.

با ظهور مدل‌های زبانی بزرگ، استفاده مدل‌های شبکه عصبی در ترجمه معکوس وارد
مرحله جدیدی شد. این مدل‌ها با استفاده از میلیارد‌ها ویژگی، قادر به بررسی
و تولید دنباله‌هایی با طول هزاران کلمه هستند و با یادگرفتن روی ترابایت‌ها
داده از اینترنت، ویژگی‌های قابل توجهی مثل تولید کد از زبان طبیعی در آن‌ها
ظهور پیدا کرده است. درک این مدل‌ها از کد این امید را ایجاد می‌کند که این
مدل‌ها بتوانند روی وظیفه ترجمه معکوس نیز خوب عمل کنند و پژوهش‌هایی در
این زمینه انجام شده است.

با این حال استفاده از مدل‌های زبانی بزرگ عام منظوره در وظیفه ترجمه معکوس
خوب عمل نمی‌کند زیرا در دادگان ورودی این مدل‌ها کد به زبان ماشین وجود
نداشته‌است یا درصد آن بسیار ناچیز بوده است. مثلا انجام ترجمه معکوس
به کمک
#notes.note[چت‌جی‌پی‌تی][ChatGPT]
که یک مدل زبانی بزرگ عام منظوره است نتایجی با
#notes.note[نزدیکی ویرایشی][edit similarity]
کمتر از چهل درصد و
#notes.note[دقت ورودی خروجی][IO accuracy]
کمتر از بیست درصد
@SLaDe
به دست آورده است. در زبان جاوا با معیار اجرای موفق مجدد
#notes.note[آزمون‌های واحد][unit tests]
چت‌جی‌پی‌تی موفق به دستیابی به درصدهای نزدیک به هشتاد شده است
@Chatgpt_Java
که این مساله به خاطر غنی‌تر بودن و سطح بالاتر بودن کد ماشین مجازی جاوا
است اما با این حال نیز تفاوت خاصی بین چت‌جی‌پی‌تی و مترجم معکوس‌های
قبلی وجود ندارد.

پروژه
#notes.note[اسلید][SLaDe]
یک مدل زبانی با ۲۰۰ میلیون ویژگی ارائه می‌دهد
@SLaDe
که با معماری
#notes.note[ترنسفرمر][Transformer]
به صورت سرتاسر روی مجموعه دادگان
#notes.note[اگزه‌بنچ][ExeBench]
که یک دادگان شامل توابع کوچک به زبان سی و نسخه ترجمه شده آن است
@ExeBench
آموزش دیده شده است و نتایج بهتری از
پروژه گیدرا و استفاده از چت‌جی‌پی‌تی به صورت خام به دست آورده است و در
بعضی از
#notes.note[محک‌ها][Benchmark]
توانسته است تا چهار برابر از مترجم معکوس‌های قبلی بهتر باشد. پروژه دیگری
به کمک
#notes.note[تنظیم دقیق][fine tune]
مدل
#notes.note[برت][BERT]
تلاش کرده تا نام متغیرها را در ترجمه معکوس بازیابی کند.
@ٰBERT_variable
یک تلاش دیگر، مدل
#notes.note[دیپ‌سیک‌کدر][DeepSeek-coder]
هفت میلیارد پارامتری روی دادگان اگزه‌بنچ تنظیم دقیق شده است و نتایح بهتری
نسبت به اسلید و دیپ‌سیک‌کدر خام به دست آورده است.
@llm4decompile

یکی از کارهای دیگر در این زمینه
#notes.note[دی‌جی‌پی‌تی][DeGPT]
@DeGPT
است که در بین پژوهش‌های مطالعه شده شاید نزدیک‌ترین مورد به ایده مطرح
شده باشد. در دی‌جی‌پی‌تی ابتدا ترجمه معکوس توسط یک مترجم معکوس پایه
انجام می‌شود و سپس مدل زبانی بزرگ در قالب سه
#notes.note[عامل][Agent]
داور و مشاور و مجری در چند مرحله خروجی مترجم معکوس
پایه را بهبود می‌دهند. در هر مرحله عامل داور تعیین می‌کند که آیا خروجی
نیاز به بهبود دارد یا خیر و اگر نیاز به بهبود دارد جنس بهبود را
از بین افزودن نظر، تغییر نام متغیرها یا ساده‌سازی ساختار کد انتخاب
می‌کند. سپس عامل مشاور متن درخواست را برحسب تغییر انتخاب شده به عامل
مجری می‌فرستد و عامل مجری، کد جدید را تولید می‌کند. سپس کد تغییر یافته
با اعداد تصادفی آزمایش می‌شود و در صورتی که نتیجه آن برابر با کد
ورودی اصلی بود، رفتار آن معادل با کد اولیه در نظر گرفته می‌شود و
فرایند تکرار می‌شود.

#align(center, text([

#text(size: .8em, [
*جدول ۱:* مقایسه مترجم‌های معکوس بررسی شده
])

#table(columns: 4, 
table.header("نام", "روش کارکرد", "خوانایی خروجی", "دقت خروجی"),
"گیدرا", "قواعد و الگوریتم‌های دستی", "کم", "با تنظیماتی که خوانایی را کاهش دهد می‌تواند زیاد باشد",
"کودا", "ال‌اس‌تی‌ام درختی + توجه", "زیاد در کدهای بسیار کوچک", "زیاد در کدهای بسیار کوچک",
"آلان جافی و سایرین", "ترجمه ماشینی آماری", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
"اسلید", "ترنسفرمر", "متوسط", "متوسط",
"بانرجی و وانگ", "برت", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
"ال‌ال‌ام برای ترجمه معکوس", "مدل زبانی بزرگ تنظیم دقیق شده", "زیاد", "متوسط",
"دی‌جی‌پی‌تی", "مدل زبانی بزرگ به صورت چند عاملی", "بهتر از مترجم معکوس پایه", "برابر با مترجم معکوس پایه",
)

]))

با تمام پیشرفت‌هایی که حاصل شده است، استفاده از مدل‌های زبانی بزرگ در
ترجمه معکوس مشکلات بنیادینی دارد. به دلیل ذات احتمالاتی این مدل‌ها، آن‌ها
هیچ وقت نمی‌توانند به دقت صددرصدی برسند. اگرچه روش‌های سنتی ترجمه معکوس
نیز دقت صددرصدی را فدای خوانایی بیشتر کد خروجی می‌کنند و در زمان تولید
کد با بیشترین خوانایی، درصد کدهای اشتباهشان حتی از روش‌های بر پایه
مدل‌های زبانی بزرگ بیشتر است، اما می‌توان آن‌ها را طوری تنظیم کرد که
در قبال خوانایی کمتر کد خروجی، حتما خواص
#notes.note[معنایی][semantic]
کد ماشین ورودی را حفظ کنند. اما در روش‌هایی که به صورت سرتاسر از
یک مدل زبانی بزرگ استفاده می‌شود و کد خروجی مستقیما توسط مدل تولید
می‌شود، نمی‌توان تضمین کرد که کد تولید شده معادل کد ماشین ورودی
اجرا شود یا حتی اصلا معتبر باشد. مثلا ممکن است که مدل زبانی بزرگ
دچار توهم شود و تابعی را صدا کند که اصلا وجود خارجی ندارد و در نتیجه
کد قابل اجرا نباشد.
@Hallucinations
در بدترین حالت، یک مهاجم می‌تواند از این عدم تضمین سواستفاده کرده و
تلاش کند تا خروجی مترجم معکوس کارکرد نرم‌افزار ورودی را نمایش ندهد. مثلا
یک بدافزار می‌تواند از طریق
#notes.note[تزریق درخواست][prompt injection]
در نام یکی از نمادها خروجی مترجم معکوس را تحت الشعاع قرار دهد و محققی
که در حال مطالعه این بدافزار است را گمراه کند.
@Prompt_injection

= ۳ #h(0.5cm) ایده

مزیت روش‌های سنتی و الگوریتمی در این است که قطعی هستند و می‌توانند به صورت
ثابت شده کدی معادل با کد ماشین ورودی تولید کنند اما قادر به تولید کد خوانا
و شبه انسانی نیستند. در مقابل، می‌توان به کمک مدل‌های زبانی بزرگ کدهای
خوانا و انسانی تولید کرد اما تضمینی وجود ندارد که این کدها رفتاری برابر
با رفتار کد ماشین ورودی داشته باشند.

ایده این است که با تلفیق مزایای هر دو روش، به یک روش ترجمه معکوس دست پیدا
کنیم که هم به صورت قطعی و تضمینی کد شبه درست خروجی دهد و هم خروجی خوانا
و قابل فهم داشته باشد. به این صورت که توسط یک روش الگوریتمی و سنتی ترجمه
معکوس آغاز شود و هنگامی که روش الگوریتمی می‌توانست از چند طریق ترجمه معکوس
را انجام دهد و همه این روش‌ها از نظر حفظ خواص معنایی درست بودند، انتخاب
خواناترین و مفهوم‌ترین گزینه به مدل زبانی بزرگ سپرده شود.

به عبارت دقیق‌تر، این فرایند برای ترجمه معکوس طی می‌شود: ابتدا کد ماشین
ورودی تبدیل به یک کد ناخوانا در زبان سطح بالا
ولی با خواص معنایی یکسان تبدیل می‌شود. سپس در هر مرحله کد فعلی تحلیل
می‌شود و بر اساس آن، چند عمل به مدل زبانی ارائه می‌شود. این که این عمل‌ها
دقیقا چند مورد هستند و چه کارهایی می‌توانند بکنند در ادامه کار مشخص
می‌شود اما خاصیت کلیدی آن‌ها این است که خواص معنایی برنامه را تغییر
نمی‌دهند و تحلیل ابتدایی این موضوع را تضمین می‌کند. سپس مدل زبانی
یکی از این عمل‌ها را انتخاب می‌کند، پارامترهای آن را ارائه می‌دهد و
نتیجه عمل را دریافت و تایید می‌کند. به این ترتیب یک مرحله کد خواناتر
می‌شود. این کار چند مرحله تکرار می‌شود تا وقتی که مدل زبانی عمل پایان
را انتخاب کند.

این روش با روش به کار رفته در دی‌جی‌پی‌تی دو تفاوت عمده دارد: یکی این که
در دی‌جی‌پی‌تی در صورتی که کد پیچیده باشد، کد تولید شده توسط مدل زبانی
با احتمال بالایی خواص معنایی کد اولیه را تغییر می‌دهد و در صورت درست عمل
کردن بررسی کننده، تغییر رد می‌شود. با رد شدن چند تغییر متوالی، مدل زبانی
دیگر نمی‌تواند کد متفاوتی را تولید کند و کار در یک مرحله متوقف می‌شود. اما
هنگام استفاده از عمل‌ها استفاده از هر عملی موجب ایجاد یک کد جدید می‌شود
و احتمال گیر کردن کمتر است. تفاوت دوم این است که بررسی برابری دو
کد به صورت صددرصدی یک مساله محاسبه‌ناپذیر است و روش‌های تقریب آن هر کدام
مشکلاتی دارند. به طور خاص روش به کار رفته در دی‌جی‌پی‌تی به طور صددرصدی
برابری خواص را تضمین نمی‌کند و صرفا از تعدادی از خطاها جلوگیری می‌کند. اما
هنگام طراحی عمل‌ها می‌توان آن‌ها را طوری انتخاب کرد که حتما خواص معنایی
را حفظ کنند.

محدود کردن گزینه‌های مدل زبانی بزرگ به منظور تضمین خواص در خروجی
قبلا هم انجام شده است. یک حرکت متداول برای ساختارمند
کردن خروجی مدل‌های زبانی
بزرگ و تضمین این که ساختار خروجی به حالت مثلا
#notes.note[جیسون][JSON]
باشد، این است که کلمات خروجی مدل را با یک
#notes.note[دستور زبان][grammar]
تطبیق دهیم و هنگام انتخاب و درج کلمات جدید، احتمال کلمات خارج از
دستور زبان را صفر در نظر بگیریم.
@Grammar_LLM
یا در تعدادی از تلاش‌ها مانند
#notes.note[آلفاپروف][AlphaProof]
گزینه‌های ارائه شده به مدل زبانی به
#notes.note[راه‌کنش‌های][tactics]
موجود در بررسی‌کننده اثبات
#notes.note[لین][Lean]
محدود شده‌اند یا در
#notes.note[آلفاجئومتری][AlphaGeometry]
گزینه‌های مدل زبانی به رسم‌های هندسی ممکن در شکل به دست آمده
محدود شده است.
@Alpha_geometry

اگرچه این خانواده از ایده‌ها باعث تضمین خواصی روی خروجی مدل‌های زبانی
بزرگ می‌شوند، اما خود آن‌ها مشکلاتی روی کیفیت خروجی ایجاد می‌کنند. مثلا
در مورد استفاده از دستور زبان برای تضمین ساختار خروجی، مطالعه‌ای نشان
داده است که استفاده بی‌ملاحظه از این روش می‌تواند منجر به ایجاد خروجی‌هایی
شود که در توزیع احتمالی مدل زبانی احتمال پایینی دارند و در نتیجه
بی‌کیفیت هستند.
@Grammar_LLM

در مورد محدود کردن گزینه‌های مدل زبانی بزرگ هنگام ترجمه معکوس نیز همین
مشکل برقرار است و ممکن است در نهایت خروجی‌های تولید شده توسط این فرایند
در توزیع مدل زبانی
#notes.note[درست‌نمایی][likelihood]
پایینی داشته باشند. در این حالت یک مدل ترجمه معکوس سرتاسر
ممکن است خروجی‌هایی تولید کند که کاملا معادل ورودی زبان ماشین نباشد
یا به دلیل ایرادی جزیی اصلا قابل اجرا نباشد، اما
در عین حال بیشتر شبیه یک کد
نوشته شده توسط انسان باشد و شمایی از کد منبع اصلی را نمایش دهد. در
مقابل خروجی تولید شده توسط مترجم معکوس محدود به عمل‌هایی که
خواص معنایی کد را حفظ می‌کنند یک کد بسیار ماشینی و ناخوانا باشد
که از نظر مدل زبانی بزرگ سرتاسر احتمال وقوع بسیار پایینی دارد و
حتی نزدیک به کد منبع اصلی نیست.

چالش اصلی ما انتخاب مجموعه‌ای از عمل‌ها روی کد است که بتوانند
در عین حال که خواص معنایی کد را حفظ می‌کنند، مانع اجرای اعمال
توسط مدل زبانی بزرگ نشوند و دست آن را خیلی نبندند تا مدل زبانی
بزرگ بتواند بدون این که نیاز به انجام اعمال طولانی و پیچیده‌ای
داشته باشد کد منبع مد نظرش را به دست آورد.

منظور از پیچیدگی اعمال، عدم نیاز به استنتاج برای انتخاب اعمال
یا نیاز به انتخاب چند عمل درست به صورت پشت سر هم بدون این که
راهنمایی برای انتخاب هر عمل در هر مرحله وجود داشته باشد است. اگر
ترجمه معکوس را مشابه یک مساله ریاضی در نظر بگیریم یک مدل زبانی
بزرگ سرتاسر فقط نیاز به پیدا کردن جواب آخر مساله دارد اما ساخت
کد منبع از طریق اعمالی که هر کدام به تنهایی خواص معنایی را حفظ
می‌کنند مشابه اثبات مساله است. و پیدا کردن اثبات به صورت ذاتی از پیدا کردن جواب آخر سخت تر است. به طور مشابه کار مدل زبانی بزرگ در ساخت
به کمک انجام عمل‌ها از ساخت جواب آخر به صورت ذاتی سخت‌تر است و هدف
انتخاب مجموعه عمل‌هایی است که از نظر تعداد و توانایی غنی باشند و
این سختی را کاهش دهند.

#align(center, text(size: .8em, [

#rotate(180deg, figure(
  image("maze2.png", width: 50%),
))

*شکل 2:* انتخاب یک مسیر به هدف با رعایت قوانین و محدودیت‌ها به صورت
ذاتی کار سخت‌تری نسبت به انتخاب یک نقطه نزدیک به هدف به صورت تصادفی، مثلا
از توزیع سبز رنگ است، اما انتخاب یک نقطه تصادفی نزدیک به هدف ممکن است
نقطه نامعتبری را انتخاب کند.

]))

= ۴ #h(0.5cm) کارهای انجام شده

به طور کلی کار به چهار بخش تقسیم می‌شود: پردازش کد ماشین ورودی، تولید
یک کد با خواص معنایی یکسان ولی ناخوانا، طراحی عمل‌هایی برای مدل زبانی
که بتواند به کمک آن‌ها خروجی را بهبود دهد بدون این که خواص معنایی
تغییر کند، و ارزیابی عملکرد.

در ابتدا قصد بر این بود که قسمت اول و دوم کار توسط یک مترجم معکوس
سنتی موجود مانند گیدرا انجام شود، ولی با مطالعه چند مترجم معکوس
به این نتیجه رسیدیم که عمده کار این مترجم‌ها روی قسمتی است که
ما قصد داریم به مدل زبانی برون سپاری کنیم. در نتیجه برای کنترل
بهتر می‌توانیم به جای استفاده از یک مترجم معکوس به عنوان پایه، از
یک هم‌گذار معکوس استفاده کنیم. این کار انجام شد و هم اکنون قسمت
یک کار که پردازش کد ماشین ورودی است به کمک یک
#notes.note[همگذار معکوس][dissassembler]
تقریبا آماده است. در این قسمت ما به کمک
#notes.note[آبج‌دامپ][Objdump]
برنامه به زبان ماشین را در قالب فایل
#notes.note[الف][Elf]
که قالب فایل‌های اجرایی در سیستم‌عامل
#notes.note[لینوکس][Linux]
است پردازش می‌کنیم و دستورهای 
#notes.note[همگذاری][assembly]
را در قالب استاندارد
#notes.note[گنو][GNU]
دریافت می‌کنیم و آن را در قالب یک داده ساختار قابل استفاده برای
کدهای بعدی در می‌آوریم.

در این پژوهش ما صرفا از نرم‌افزارهایی که برای ماشین‌های
اینتل ۶۴ بیتی ترجمه شده‌اند پشتیبانی می‌کنیم. نود درصد پردازنده‌های
رایانه‌های رومیزی و رایانه‌های
#notes.note[کارساز][server]
موجود در
#notes.note[مراکز داده][data center]
از معماری اینتل استفاده می‌کنند و عمده استفاده از مترجم‌های معکوس روی
همین معماری است. افزودن معماری‌های دیگر می‌تواند در آینده انجام شود
اما هدف این پژوهش به کارگیری مدل‌های زبانی بزرگ به صورت قاعده‌مند
و کنترل شده در زمینه مترجم‌های معکوس است و پشتیبانی از یک معماری هم
برای بررسی این موضوع کافیست.

معماری اینتل مجموعه دستور پیچیده‌ای دارد و هم از نظر تعداد و هم
از نظر عملگرها نسبت به بقیه مجموعه دستورهای مطرح مانند
#notes.note[آرم][ARM]
و
#notes.note[ریسک پنج][RISC-V]
پیچیده‌تر است. این مساله کار پردازش کد ماشین را سخت می‌کند اما ممکن
است به دلیل غنی‌تر بودن دستورات، اطلاعات بیشتری در کد ماشین نگه داشته
شود و فرایند ترجمه معکوس کمی آسان‌تر شود. با این حال نه سختی
پردازش دستورات و نه آسان‌تر شدن ترجمه معکوس روی انتخاب مجموعه دستور
اینتل تاثیری نداشته است و صرفا به دلیل پر استفاده بودن آن را انتخاب
کردیم.

در یک فایل اجرایی الف، کد ماشین به صورت دودویی قرار دارد. در معماری
اینتل یک نوع دستور ممکن است به چند طریق به کد ماشین تبدیل شود و
به دست آوردن معنی دستورها از روی کد ماشین کاری نابدیهی است. خوشبختانه
آبج‌دامپ این کار را برای ما انجام می‌دهد و دستورها را در قالب
استاندارد گنو به ما تحویل می‌دهد. هر خط از خروجی آبج‌دامپ شامل آدرس
این قسمت، بایت‌های کد ماشین به صورت هگز، و کد هم‌گذاری معادل این کد
ماشین است.

کد هم‌گذاری ماشین اینتل در استاندارد گنو از چند قسمت تشکیل شده
است: پیشوند‌ها،
#notes.note[یادمان][mnemonic]
و عمل‌گرها. یادمان همان نام دستور است که نشان می‌دهد دستور با عمل‌گرهایش
چه کاری انجام می‌دهد. ما از ده‌ها یادمان پشتیبانی می‌کنیم و در صورتی
که یک یادمان را تشخیص ندهیم، با خطا متوقف می‌شویم زیرا احتمالا در ادامه
نیز نمی‌توانیم رفتار کاملا درستی با این دستور و در نتیجه این برنامه داشته
باشیم. نکته قابل توجه دیگر این است که در نمایش گنو اندازه عملگرها نیز
در قالب یک حرف به یادمان می‌چسبد
و این حرف را تشخیص داده و جدا می‌کنیم. هر دستور می‌تواند یک یا چند عملگر
داشته باشد و کار را روی آن‌ها انجام دهد. مثلا دستور جمع دو عملگر می‌گیرد
و مقدار آن‌ها را با هم جمع می‌کند و در عملگر اول ذخیره می‌کند. هر عملگر
می‌تواند یک
#notes.note[ثبات][register]
یا یک آدرس از حافظه یا یک مقدار ثابت یا یک برچسب باشد. در هنگام
پردازش، به کمک چند
#notes.note[عبارت منظم][regular expression]
این عملگرها ابتدا از یک دیگر جدا می‌شوند و سپس نوع و مقدار آن‌ها تشخیص
داده شده و ذخیره می‌شود. پیشوندها نیز کلمات کلیدی‌ای هستند که می‌توانند
قبل از یک دستور ظاهر شوند و معنی آن را تغییر دهند. مثلا پیشوند قفل
به این معنی است که در حین اجرای دستور خطوط درگیر از حافظه پنهان
به صورت انحصاری در اختیار این هسته از پردازنده هستند و مقادیر مرتبط
حافظه در هنگام اجرای دستور توسط هسته‌های دیگر تغییر نخواهند کرد.

فرایند پردازش کد ماشین ورودی روی دادگان آزمایش و چند برنامه واقعی
اجرا شد و به طور موفقیت آمیز همه دستورها در آن‌ها پردازش شد و یادمان
و عمل‌گرها به درستی تشخیص داده شدند. با این حال قطعا همه فضای دستور
اینتل پوشانده نشده است و ممکن است در ادامه تغییراتی در این قسمت
نیاز شود.

با این که پردازش کد ماشین ورودی تقریبا انجام شده است، 
اما قسمت دوم کار هنوز حتی در سطح مقدماتی
و برای کدهای خاص نیز آغاز نشده است و در ادامه باید
انجام شود.

در رابطه با طراحی عمل‌ها برای استفاده مدل زبانی، عمل‌های دقیق باید
بعد از آماده شدن قسمت دوم طراحی شوند. اما برای امکان سنجی ایده، به
عنوان یک مثال تلاش کردیم تا سه عملیات تغییر نام یک متغیر، تبدیل
دسترسی حافظه خطی به
حافظه ساختار یافته، و جدا سازی یک متغیر به دو متغیر
را توسط مدل‌های زبانی موجود انجام دهیم. متاسفانه
به صورت پیش‌فرض مدل‌ها عملکرد خوبی در این زمینه نداشتند. آن‌ها قادر به
انتخاب یک عمل از بین عمل‌های ارائه شده نبودند و کد را خارج از عمل‌های
تعیین شده تغییر می‌دادند.

در ادامه تلاش کردیم با تنظیم دقیق یک مدل
#notes.note[لاما][Llama]
با هفت میلیارد پارامتر سعی کنیم تا مدل قواعد عمل‌ها را رعایت کند. برای
این کار از سایت
#notes.note[هاگینگ فیس][Hugging face]
مدل را روی
#notes.note[گوگل کولب][Google colab]
بارگیری کردیم و با روش
#notes.note[لرا][LoRA]
@LoRA
تنظیم دقیق را شروع کردیم. دادگان تنظیم دقیق شامل صد داده به صورت
ماشینی تولید شده به ازای هر عملیات بود. این
روش کار کرد ولی اجرای آن بسیار سخت و زمان‌بر بود و کار را محدود به
مدل‌های کوچک می‌کرد. مدل‌های بزرگ‌تر از هفت میلیارد پارامتر روی جی‌پی‌یوهای
موجود در گوگل کولب جا نمی‌شوند و هم چنین در این روش نمی‌توان از مدل‌های
غیر متن‌باز مثل مدل‌های منتشر شده توسط شرکت
#notes.note[اوپن‌ای‌آی][OpenAI]
استفاده کرد. حتی تنظیم دقیق همین مدل هفت میلیارد پارامتری چندین
ساعت زمان می‌برد و به دلیل این که نسخه رایگان گوگل کولب در استفاده‌های
طولانی به نشست خاتمه می‌دهد، انجام این کار سختی فراوانی داشت.

در نهایت به کمک
#notes.note[یادگیری در زمینه][In-context learning]
@InContextLearning
توانستیم بدون تنظیم دقیق مدل خروجی مطلوب را بگیریم که امکان استفاده
از مدل‌های بزرگ‌تر و غیرمتن‌باز را نیز فراهم می‌کند. در این روش از هر عمل
دو مثال و یک مثال که چند عمل را به صورت متوالی اعمال می‌کند درون
زمینه قرار دادیم و مدل به کمک آن توانست از الگو پیروی کند و خروجی
مطابق انتظار تولید کند.


#align(center, text(size: .8em, [

#grid(columns: 2,
image("gpt2.png", width: 70%),
image("gpt.png", width: 80%)
)

*شکل 3:* به صورت پیش‌فرض مدل قادر به تولید پاسخ در قالب تعیین شده
نیست و متن‌های اضافی تولید می‌کند (تصویر سمت راست) اما به کمک یادگیری
در زمینه می‌توان آن را مجبور کرد که در قالب تعیین شده خروجی دهد.
(تصویر سمت چپ)

]))

با این حال این
کار به صورت آزمایشی انجام شد و در استفاده از عمل‌های واقعی که طراحی
آن‌ها بعد از مرحله دوم باید انجام شود ممکن است تفاوت‌هایی ایجاد شود.

= ۵ #h(0.5cm) نحوه ارزیابی

به طور کلی هدف مترجم‌های معکوس تولید کدی با زبان سطح بالا است که
هم معادل کد ماشین ورودی باشد و هم خوانا و سطح بالا مشابه کدهای
نوشته شده توسط انسان باشد. این دو هدف تا حدی در تقابل هستند
و یک
#notes.note[بده بستان][tradeoff]
بین آن‌ها جریان دارد. مثلا تبدیل کد ماشین به زبان
همگذاری
ساختار معنایی برنامه را در حد بسیار بالایی حفظ می‌کند اما از
نظر خوانایی اصلا خوب نیست. با توجه به این بده بستان، عملکرد هر
مترجم معکوس باید در هر دو بعد بررسی شود.

== ۱.۵ #h(0.5cm) ارزیابی از منظر حفظ ساختار معنایی

در زمینه حفظ ساختار معنایی، معمولا عملکرد به این صورت سنجیده می‌شود
که یک معیار به صورت صفر یا یک مشخص می‌کند که آیا کد منبع خروجی با
کد ماشین ورودی از لحاظ معنایی دقیقا یکسان هست یا خیر، و سپس این
معیار روی چندین آزمون اجرا می‌شود و درصد نسبت تعداد درست‌ها به کل به
عنوان نتیحه ارزیابی در نظر گرفته می‌شود.

معیارهای مختلفی برای در نظر گرفتن برابری دو کد وجود دارد که هر کدام
ویژگی‌های خودشان را دارد. چند مورد از آن‌ها را در این جا ذکر می‌کنیم. در
موارد زیر به ترتیب هر مورد از مورد بعدی سخت‌گیرانه تر است و اگر دو کد
از نظر یک مورد برابر باشند از نظر موارد بعدی نیز حتما برابر هستند.

*ترجمه کد منبع و بررسی برابری کدهای ماشین:* در این روش، کد منبع
تولید شده مجددا توسط مترجم به زبان ماشین ترجمه می‌شود و کد ماشین
ایجاد شده با کد ماشین اصلی مقایسه می‌شود و در صورت برابری
جز به جز، ترجمه معکوس درست در نظر گرفته می‌شود. اگرچه این روش
پیاده سازی بسیار راحتی دارد ولی بسیار سخت‌گیرانه است و به دلیل
بهینه‌سازی‌هایی که مترجم‌های مرسوم انجام می‌دهند، پیش‌بینی کد ماشین
خروجی به ازای یک کد ورودی خاص با دقت بالا عملا غیرممکن است و
در نتیجه تولید کد در این سطح از برابری برای مترجم‌های معکوس قابل
دستیابی نیست.

*بررسی برابری درخواست‌های ورودی و خروجی:* در بررسی برابری دو کد، این که
دقیقا چه دستورهای ماشینی اجرا می‌شود در عمل اهمیت خاصی ندارد، بلکه
رفتار کد مهم است. در بررسی برابری درخواست‌های ورودی و خروجی، به جای
بررسی برابری جز به جز کد‌های ماشین، صرفا بررسی برابری ورودی و خروجی‌های
برنامه که معمولا از طریق
#notes.note[فراخوانی سامانه‌ای][system Call]
انجام می‌شوند بررسی می‌شود. چون بهینه‌سازی‌های مترجم‌ها نباید رفتار
برنامه را تغییر دهند، مترجم‌های معکوس می‌توانند روی کد ماشین حاصل
شده از کد منبعی که تولید کرده‌اند حساب کنند و برابری با این معیار
را به دست آورند. با این حال، بررسی این برابری سخت‌تر از بررسی برابری
بالاست و در صورتی که بخواهیم به ازای هر حالت از ورودی‌های ممکن این
برابری را بررسی کنیم، باید به روش‌هایی مثل
#notes.note[اجرای نمادی][symbolic executation]
متوسل شویم
@DHelix
یا این که از فضای حالت ورودی‌ها چند نمونه تصادفی برداریم
@Testing_decompiler
که هر کدام از این روش‌ها محدودیت‌های خودشان را دارند.

*اجرای آزمون‌های واحد:* برای کدهای واقعی، اندازه‌گیری برابری کامل ورودی
و خروجی‌ها کار دشواری است و روش‌هایی مثل اجرای نمادی نمی‌توانند
روی کدهای واقعی در زمان قابل قبولی کار کنند. خوشبختانه در بعضی از
پروژه‌های واقعی از آزمون‌های نرم‌افزاری مثل آزمون‌های واحد استفاده
می‌شود و ما می‌توانیم این آزمون‌ها را روی خروجی مترجم معکوس نیز اجرا
کنیم و در صورت پاس شدن همه آن‌ها، ادعای برابری خروجی مترجم معکوس
با کد اصلی را بکنیم. اگرچه پاس شدن آزمون‌های واحد لزوما به معنی برابری
کد در همه زمینه‌ها نیست، اما توسعه‌دهندگان نرم‌افزار تلاش می‌کنند تا
نیازمندی‌های نرم‌افزارشان را در آزمون‌ها لحاظ کنند و حالت‌های خاص را
آزمایش کنند. در نتیجه در صورتی که خروجی مترجم معکوس آزمون‌های واحد را
پاس کند می‌توان گفت که تا حد خوبی خواص برنامه اصلی را حفظ کرده است.

== ۲.۵ #h(0.5cm) ارزیابی از منظر خوانایی کد

ارزیابی از منظر خوانایی کد سخت تر از ارزیابی برابری معنایی است چون
خوانایی کد مفهومی انسانی و بدون تعریف مشخص است. با این حال در
پژوهش‌های پیشین تلاش‌هایی برای ارزیابی از این منظر انجام شده و معیارهایی
به دست آمده است که آن‌ها را ذکر می‌کنیم.

*شباهت ویرایشی:* فاصله ویرایشی بین دو متن، برابر کمینه تعداد عمل‌های
درج، حذف و جایگزینی یک حرف است که متن اول را به متن دوم تبدیل کند. در
این روش، فاصله ویرایشی بین کد منبع اصلی و خروجی مترجم معکوس در نظر گرفته
می‌شود و هر چه این فاصله کمتر باشد، کد خواناتر در نظر گرفته می‌شود. فرض
پنهان در این روش این است که تنها یک حالت کد خوانا وجود دارد که می‌تواند
رفتار مورد نظر ما را پیاده‌سازی کند. با این که این فرض به صورت کلی درست
نیست اما در کدهای ساده با تقریب خوبی درست است و همه کدهای انسانی با
یک رفتار خاص شبیه به هم هستند.

*مقایسه پیچیدگی:* در صورتی که اندازه خروجی مترجم معکوس بسیار پیچیده‌تر از
اندازه کد منبع اصلی باشد، نشان می‌دهد که مترجم معکوس نتوانسته است
کد قابل درک و خوانایی تولید کند.
@Metrics
برای مقایسه پیچیدگی، می‌توان معیارهایی
مثل اندازه کد یا
#notes.note[پیچیدگی شناختی][Cognitive Complexity]
@Cognitive
یا تعداد پرش‌ها یا موارد مشابه را اندازه‌گیری کرد.

*پرسش از متخصص انسانی:* چون هدف از خوانایی کد، قابل فهم بودن آن برای
انسان است، دقیق‌ترین روش اندازه‌گیری خوانایی نظرسنجی از انسان است. با این
حال این کار هزینه فراوانی دارد و نمی‌توان روی دادگان بزرگی آن را انجام
داد.

*پرسش از مدل زبانی بزرگ:* مشابه پرسش از انسان، یک مدل زبانی بزرگ می‌تواند
از منظر یک انسان کدهای خوانا را از ناخوانا تشخیص دهد و این کار را در
ابعاد وسیع‌تری نسبت به پرسش از انسان انجام دهد. البته در این روش باید
دقت کرد که از مدل زبانی ارزیابی کننده در حین فرایند ترجمه معکوس استفاده
نکرد زیرا در غیر این صورت نتایج ممکن است دچار سوگیری شود.

== ۳.۵ #h(0.5cm) دادگان

برای اندازه‌گیری و مقایسه معیارهای گفته شده برای مترجم معکوس‌های مختلف
نیاز به دادگان وسیع و متنوعی داریم که شامل الگوهای مختلف کد که توسط
انسان نوشته می‌شود باشد و مترجم معکوس را در حوزه‌های مختلف و سبک‌های
مختلف برنامه‌نویسی به چالش بکشد.

یکی از ابزارهایی که برای آزمایش مترجم‌ها و مترجم‌های معکوس استفاده
می‌شود پروژه
#notes.note[سی‌اسمیت][CSmith]
است
@CSmith
که با تولید کدهای سی که حالت‌های خاص اجرا را ایجاد می‌کنند، سعی در
پیدا کردن باگ در مترجم‌های سی دارد.
با این که این پروژه بسیار موفق بوده است و توانسته است در بسیاری از
مترجم‌های مطرح مشکلاتی را پیدا کند و در زمینه مترجم معکوس نیز به کار
رفته است
@Testing_decompiler
@Neutron
اما به دلیل این که کدهای تولید شده توسط آن بسیار ماشینی است
و مدل‌های زبانی روی کدهای ماشینی با خواص عجیب و غریب که به نیت
آزمایش حالت‌های خاص مترجم تولید شده است آموزش ندیده است و عملکرد
آن روی این گونه از کدها مبهم است. در نتیجه ما از سی‌اسمیت استفاده
نمی‌کنیم و روی دادگانی که به کدهای جهان واقعی نزدیک‌تر هستند
تمرکز می‌کنیم. 

مجموعه دادگان اگزه‌بنچ شامل قطعات کوچک کد سی به همراه نسخه ترجمه‌شده
آن‌ها و تعدادی آزمون واحد و فراداده‌های دیگر است. این قطعات از
کدهای واقعی مثل کدهای موجود در گیت‌هاب استخراج شده‌اند
@ExeBench
و در کارهای مشابه مربوط به مترجم معکوس استفاده شده‌اند
@SLaDe
پس به نظر می‌رسد که این دادگان برای استفاده ما مناسب است.

= ۶ #h(0.5cm) مراحل ادامه کار

همان‌طور که در بخش ۴ مطرح شد، پردازش کد ماشین ورودی تقریبا انجام شده
است ولی ایجاد کد منبع ابتدایی هنوز آغاز نشده است. قبل از این که
بتوان روی طراحی عمل‌ها یا هر قسمت دیگری کار کرد، این بخش باید
تکمیل شود و یک کد ابتدایی تولید شود.

بعد از تولید کد ابتدایی، می‌توان کار بر روی طراحی عمل‌ها را آغاز
کرد. با این حال قصد داریم که در اسرع وقت و با عمل‌های حداقلی
فرایند ارزیابی اولیه را آغاز کنیم و خروجی مترجم معکوس را از ابعاد
مختلف بسنجیم. با این کار می‌توان تاثیر هر کار انجام شده را اندازه‌گیری
کرد و روی کارهای موثرتر سرمایه‌گذاری کرد. راه‌اندازی 
#notes.note[چرخه بازخورد][feedback loop]
و کوچک کردن طول این چرخه می‌تواند هم گزارش‌دهی وضعیت را آسان‌تر
کند و هم به کمک بازخوردها، مسیر اصلاح شده و پژوهش به مسیر درست هدایت شود.

بعد از راه‌اندازی زیرساخت ارزیابی، می‌توان به صورت گام‌به‌گام
به بهبود عملکرد پرداخت. هر گام می‌تواند شامل یکی از کارهای زیر باشد:

*افزودن عمل‌های بیشتر:* همان‌طور که مطرح شد، محدودیت عمل‌ها می‌تواند
مانع رسیدن مدل زبانی بزرگ به کد خوانایی که در توزیع احتمالاتی‌اش
احتمال بالایی دارد شود. با افزایش تعداد عمل‌ها انتظار می‌رود که شاهد
بازتر شدن دست مدل زبانی در اعمال تغییرات و در نتیجه انتخاب کدهای
بهتر و خواناتر توسط آن باشیم.

*بررسی دلیل عدم تولید کد مناسب:* به دلایل مختلفی ممکن است کد مناسب
و خوانا تولید نشود. مثلا مدل زبانی می‌تواند از عمل‌های موجود
استفاده نکند یا در شرایطی خاص به یک عملیات خاص نیاز داشته باشد. بررسی
علل شکست خوردن مدل زبانی در مثال‌های خاص می‌تواند حوزه خوبی برای
وقت گذاشتن در راستای بهبود کیفیت خروجی باشد.

*استفاده از مدل‌های زبانی پیشرفته‌تر:* امروزه مدل‌های زبانی بزرگ یکی از
موضوعات داغ هوش مصنوعی هستند و هر روز مدل‌ها، روش‌ها و ترفندهای جدیدی
در این زمینه ظهور می‌کنند. با استفاده از مدل‌ها یا ابزارهای جانبی
جدیدتر یا پیشرفته‌تر یا خاص منظوره‌تر برای کاربرد تولید کد و پردازش
زبان ماشین، می‌توان انتظار داشت که خروجی بهبود یابد.

*ایجاد مثال‌های بیشتر برای یادگیری در زمینه:*
همان طور که در قسمت ۴ مطرح شد، مشاهده شد که یادگیری در زمینه برای
این که مدل بتواند به کمک عمل‌های طراحی شده کد را بهبود دهد
و در قالب تعیین شده حرکت کند ضروری است. می‌توان انتظار داشت که
با بهبود و افزایش تعداد مثال‌ها، عملکرد مدل بهبود پیدا کند. مثال‌های
جدید می‌تواند از تلاش‌های خوب خود مدل یا اصلاح دستی تلاش‌های ضعیف
مدل به دست آید.

#align(center, text([

#text(size: .8em, [
*جدول ۲:* زمان‌بندی ادامه پژوهش  
])

#table(columns: 2, [
  تکمیل پردازش کد ماشین ورودی و تولید یک کد ابتدایی
],
[
  ۳۰ بهمن ۱۴۰۳
],
[
  ایجاد عملگرهای ابتدایی و آغاز استفاده از مدل زبانی بزرگ
],
[
  ۳۰ اسفند ۱۴۰۳
],
[
  ایجاد زیرساخت ارزیابی اولیه و ایجاد
  چرخه بازخورد
],
[
  ۱۵ فروردین ۱۴۰۴
],
[
  بهبود خروجی به کمک افزایش عمل‌های پیشتیبانی شده و بهبود اجزای دیگر
],
[
  ۲۰ اردیبهشت ۱۴۰۴
],
[
  ارزیابی نهایی و مقایسه عملکرد با روش‌های موجود
],
[
  ۳۰ اردیبهشت ۱۴۰۴
],
[
  تکمیل پایان‌نامه و دفاع از تز
],
[
  ۳۰ خرداد ۱۴۰۴
],
)

]))

= مراجع

#text(dir: ltr, font: "Times New Roman", size: 9pt)[

#bibliography("ref.bib", title: none)

]

= واژه نامه

#text(dir: ltr)[
#grid(columns: (1fr, 1fr, 1fr), 
[
  #notes.display(0)
],
[
  #notes.display(1)
],
[
  #notes.display(2)
])
]